{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71f39c30-81bc-43c6-a39c-f2bdb3953c37",
   "metadata": {},
   "source": [
    "# 4th April Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25a6678-f90b-42f4-a54b-8807644f5164",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6e6aa8a4-7b56-431f-b008-3f1733ab1a20",
   "metadata": {},
   "source": [
    "## Q1. Describe the decision tree classifier algorithm and how it works to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b504ab60-cd19-43ef-b614-c1d0e32041d1",
   "metadata": {},
   "source": [
    "- > Decision tree classifier is used to solve calssification problem.\n",
    "\n",
    "- > It creates tree based on the features.\n",
    "\n",
    "- > The tree will split itself untile we don't find leaf node.\n",
    "\n",
    "- > We uses Entropy and Gini Impurity to check whether the split is pure or impure.\n",
    "\n",
    "- > If the node is pure so we will consider it as leaf node.\n",
    "\n",
    "* Prediction\n",
    "\n",
    "- > The new data will travel tree according to different features.\n",
    "\n",
    "- > When that data reaches leaf node the majority class lable will assign to it as prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59eee7b-c798-474d-a78e-0eb17f7b2705",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c8129ca-857b-43c7-bdf9-69dcac7e7758",
   "metadata": {},
   "source": [
    "## Q2. Provide a step-by-step explanation of the mathematical intuition behind decision tree classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83022026-e4cd-4b0d-b891-33b74bd9a3cd",
   "metadata": {},
   "source": [
    "- > We uses three mathematical techniques to train our best decision tree classification.\n",
    "\n",
    "1. Entropy\n",
    "\n",
    "2. Gini Impurity\n",
    "\n",
    "- > This two techniques are used to check whether node is pure or impure.\n",
    "\n",
    "3. Information Gain\n",
    "\n",
    "- > This technique is used to take decion of which feature we should select first to train the best model.\n",
    "\n",
    "* Mathematical Intution\n",
    "\n",
    "1. Entropy : -p+ Log2 p+ -p- Log2 p-\n",
    "\n",
    "2. Gini Impurity : 1 - Σ (P) ** 2\n",
    "\n",
    "3. Information Gain : H(S) - Σ |Sv| / |S| * H(Sv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c61fce-6bce-4387-b51f-5b17d7d74987",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f55929d2-008e-4263-a34c-2acbffbdd25a",
   "metadata": {},
   "source": [
    "## Q3. Explain how a decision tree classifier can be used to solve a binary classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "125c6cdc-f541-4d80-a82b-6386855af1a2",
   "metadata": {},
   "source": [
    "- > In binary classification we split the tree according two categories(0 and 1).\n",
    "\n",
    "- > With the help of entropy and gini impurity we can check that our split is pure or impure.\n",
    "\n",
    "- > Our goal is to maximize the information gain.\n",
    "\n",
    "- > We can also apply best parameters with the help of prepruning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edcd52fc-45f0-412a-8585-8d63d408bce2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5c49db13-0ea8-4df5-acee-5477c8d9b210",
   "metadata": {},
   "source": [
    "## Q4. Discuss the geometric intuition behind decision tree classification and how it can be used to make predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509fe34b-7093-4dfb-aff8-4e3d9e3e8a0a",
   "metadata": {},
   "source": [
    "- > Decision tree splits itself into different categories.\n",
    "\n",
    "- > It will check the purity of child node.\n",
    "\n",
    "- > If the child node is pure so we will consider it as leaf node.\n",
    "\n",
    "- > And if any child node is impure so we will split it until it becomes leaf node.\n",
    "\n",
    "- > When we enter new data,it will travel nodes accrding to conditions and reach the leaf node.\n",
    "\n",
    "- > It will give majority class label to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58e049f-c25c-483d-8a16-2b6bc3128d07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "38dd6cfb-eb39-4911-8308-e4cec2adb260",
   "metadata": {},
   "source": [
    "## Q5. Define the confusion matrix and describe how it can be used to evaluate the performance of a classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bea9e78-6b3b-4f6a-a471-c58558cac8a8",
   "metadata": {},
   "source": [
    "* Confusion Matrix\n",
    "\n",
    "- > A confusion matrix is a table used to evaluate the performance of a classification model. It provides a detailed breakdown of the model's predictions and the actual outcomes. In the context of binary classification, the confusion matrix has four entries:\n",
    "\n",
    "True Positive (TP): Instances that are actually positive and were correctly classified as positive by the model.\n",
    "\n",
    "True Negative (TN): Instances that are actually negative and were correctly classified as negative by the model.\n",
    "\n",
    "False Positive (FP): Instances that are actually negative but were incorrectly classified as positive by the model (Type I error).\n",
    "\n",
    "False Negative (FN): Instances that are actually positive but were incorrectly classified as negative by the model (Type II error).\n",
    "\n",
    "- > Confusion matrix is a valuable tool for evaluating the performance of a classification model, providing insights into its strengths and weaknesses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3929bc6-3a5d-4a94-908d-053663d4ee5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bed9a7df-1415-414e-8a87-41da216b3000",
   "metadata": {},
   "source": [
    "## Q6. Provide an example of a confusion matrix and explain how precision, recall, and F1 score can be calculated from it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4607e0b-b264-4b80-ab69-e16e5fb72516",
   "metadata": {},
   "source": [
    "- > After predicting the values we can get some values for confusion matrix.\n",
    "\n",
    "TP - 3 , TN - 1 , FP - 2 , FN - 1\n",
    "\n",
    "- > We the help of above values we can easily calculate precision,recall and F1 Score.\n",
    "\n",
    "* Formula :\n",
    "\n",
    "Precision : TP / TP + FP\n",
    "\n",
    "Recall : TP / TP + FN\n",
    "\n",
    "F1 Score : 2 * (Precision * Recall) / (Precision + Recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75a63ba-27ff-458d-b0b4-ea6054114bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8edfbd3e-dba8-4d89-8d0d-62d20b5c88e2",
   "metadata": {},
   "source": [
    "## Q7. Discuss the importance of choosing an appropriate evaluation metric for a classification problem and explain how this can be done."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5414e47c-1e66-41df-86d6-4f4353a7bc35",
   "metadata": {},
   "source": [
    "- > Choosing an appropriate evaluation metric is crucial in a classification problem because it directly influences how you assess the performance of your model and, ultimately, the decisions you make based on that assessment. Different classification problems may prioritize different aspects of model performance, and choosing the right metric ensures that your evaluation aligns with the goals and requirements of the specific application. \n",
    "\n",
    "- > By hyperparameter tuning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998d7b6c-49c3-469b-8341-66f55459cdd1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "035efd62-c79e-4b6e-b3ed-39b03319521b",
   "metadata": {},
   "source": [
    "## Q8. Provide an example of a classification problem where precision is the most important metric, and explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a58f11-2df2-4c4a-92f7-717f01eaedba",
   "metadata": {},
   "source": [
    "Example : Spam Emails Prediction.\n",
    "\n",
    "- > Let consider if our email is not a spam but model predict it is spam so that can be a problem for us.\n",
    "\n",
    "- > This is FP senario.\n",
    "\n",
    "- > In the senario of FP we should use precision.\n",
    "\n",
    "- > A high precision value indicates that when the spam filter labels an email as spam, it is very likely to be correct.\n",
    "\n",
    "- > Prioritizing precision helps maintain a positive user experience by ensuring that the spam filter is not overly aggressive in classifying non-spam emails."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c761cab7-f8de-4c7e-904e-2ce01498d147",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1c7d26a-b857-4d4c-a525-91982dfae922",
   "metadata": {},
   "source": [
    "## Q9. Provide an example of a classification problem where recall is the most important metric, and explain why."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0144fab4-02c4-484a-8f9c-0e0b1a75cac3",
   "metadata": {},
   "source": [
    "Example : Diabetes Prediction\n",
    "\n",
    "- > If the person has diabetes and model predict that the person doesn't have diabetes, so it can become a big problem for anyone.\n",
    "\n",
    "- > This is the scenario of FN.\n",
    "\n",
    "- > In FN scenario we should choose recall.\n",
    "\n",
    "- > High recall means that the model is effective in capturing a large proportion of true positive cases\n",
    "\n",
    "- > Missing a positive case in this scenario could lead to delayed diagnosis and treatment.\n",
    "\n",
    "- > "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
